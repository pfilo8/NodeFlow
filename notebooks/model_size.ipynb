{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from probabilistic_flow_boosting.models.nodeflow import NodeFlow, NodeFlowDataModule\n",
    "from probabilistic_flow_boosting.extras.datasets.uci_dataset import UCIDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_datasets = [\n",
    "    'concrete',\n",
    "    'energy',\n",
    "    'kin8nm',\n",
    "    'naval_propulsion_plant',\n",
    "    'power_plant',\n",
    "    'protein_tertiary_structure',\n",
    "    'wine_quality_red',\n",
    "    'yacht'\n",
    "]\n",
    "\n",
    "def generate_samples_nodeflow(model, datamodule, observation, num_samples: int = 1000):\n",
    "    samples = model._sample(observation, num_samples)\n",
    "\n",
    "    samples_size = samples.shape\n",
    "    samples: np.ndarray = samples.detach().cpu().numpy()\n",
    "    samples: np.ndarray = samples.reshape((samples_size[0] * samples_size[1], samples_size[2]))\n",
    "    samples: np.ndarray = datamodule.target_scaler.inverse_transform(samples)\n",
    "    samples: np.ndarray = samples.reshape((samples_size[0], samples_size[1], samples_size[2]))\n",
    "    samples: np.ndarray = samples.squeeze()\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete\n",
      "Total params: 4959763+-10832838\n",
      "Time eval: 0.601+-0.484\n",
      "energy\n",
      "Total params: 923144+-1696191\n",
      "Time eval: 0.52+-0.207\n",
      "kin8nm\n",
      "Total params: 10486159+-7801478\n",
      "Time eval: 1.17+-0.474\n",
      "naval_propulsion_plant\n",
      "Total params: 3167099+-4415772\n",
      "Time eval: 0.636+-0.264\n",
      "power_plant\n",
      "Total params: 894201+-772524\n",
      "Time eval: 0.645+-0.226\n",
      "protein_tertiary_structure\n",
      "Total params: 531659+-623584\n",
      "Time eval: 0.518+-0.13\n",
      "wine_quality_red\n",
      "Total params: 110592+-66932\n",
      "Time eval: 0.437+-0.127\n",
      "yacht\n",
      "Total params: 76663+-56485\n",
      "Time eval: 0.268+-0.074\n"
     ]
    }
   ],
   "source": [
    "for DATASET in uci_datasets:\n",
    "    IDX = 0\n",
    "    \n",
    "    ## Load data\n",
    "    x_train = UCIDataSet(\n",
    "        filepath_data=f\"../data/01_raw/UCI/{DATASET}/data.txt\",\n",
    "        filepath_index_columns=f\"../data/01_raw/UCI/{DATASET}/index_features.txt\",\n",
    "        filepath_index_rows=f\"../data/01_raw/UCI/{DATASET}/index_train_{IDX}.txt\"\n",
    "    ).load()\n",
    "    y_train = UCIDataSet(\n",
    "        filepath_data=f\"../data/01_raw/UCI/{DATASET}/data.txt\",\n",
    "        filepath_index_columns=f\"../data/01_raw/UCI/{DATASET}/index_target.txt\",\n",
    "        filepath_index_rows=f\"../data/01_raw/UCI/{DATASET}/index_train_{IDX}.txt\"\n",
    "    ).load()\n",
    "    x_test = UCIDataSet(\n",
    "        filepath_data=f\"../data/01_raw/UCI/{DATASET}/data.txt\",\n",
    "        filepath_index_columns=f\"../data/01_raw/UCI/{DATASET}/index_features.txt\",\n",
    "        filepath_index_rows=f\"../data/01_raw/UCI/{DATASET}/index_test_{IDX}.txt\"\n",
    "    ).load()\n",
    "    y_test = UCIDataSet(\n",
    "        filepath_data=f\"../data/01_raw/UCI/{DATASET}/data.txt\",\n",
    "        filepath_index_columns=f\"../data/01_raw/UCI/{DATASET}/index_target.txt\",\n",
    "        filepath_index_rows=f\"../data/01_raw/UCI/{DATASET}/index_test_{IDX}.txt\"\n",
    "    ).load()\n",
    "\n",
    "    x_train_tensor = torch.Tensor(x_train.values)\n",
    "    x_test_tensor = torch.Tensor(x_test.values)\n",
    "    y_train_tensor = torch.Tensor(y_train.values)\n",
    "    y_test_tensor = torch.Tensor(y_test.values)\n",
    "\n",
    "    datamodule = NodeFlowDataModule(x_train, y_train, x_test, y_test, split_size=0.8, batch_size=2048)\n",
    "    datamodule.target_scaler.fit(datamodule.y_tr)\n",
    "\n",
    "    # model_filepath = f\"../data/nodeflow/UCI/{DATASET}/model_{IDX}\"\n",
    "    \n",
    "\n",
    "    ## Do things\n",
    "    total_params = []\n",
    "    time_eval = []\n",
    "    print(DATASET)\n",
    "    for i in range(20):\n",
    "        if DATASET == 'protein_tertiary_structure' and i == 5:\n",
    "            break\n",
    "\n",
    "        model_filepath = f\"../data/06_models/UCI/{DATASET}/model_uci_{i}\"\n",
    "        nodeflow = NodeFlow.load(model_filepath, map_location=\"cpu\")\n",
    "        nodeflow.eval()\n",
    "        observation = x_test_tensor[i, :].reshape(1, -1)\n",
    "\n",
    "        total_params.append(sum(\n",
    "        \tparam.numel() for param in nodeflow.parameters()\n",
    "        ))\n",
    "        \n",
    "        time_start = time.time()\n",
    "        nodeflow_samples = generate_samples_nodeflow(nodeflow, datamodule, observation, num_samples=1000)\n",
    "        time_eval.append(time.time() - time_start)\n",
    "\n",
    "        del nodeflow\n",
    "    print(f\"Total params: {np.mean(total_params).astype(int)}+-{np.std(total_params).astype(int)}\")\n",
    "    print(f\"Time eval: {np.mean(time_eval).round(3)}+-{np.std(time_eval).round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nodeflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
