{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as dist\n",
    "import umap\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, QuantileTransformer\n",
    "\n",
    "from probabilistic_flow_boosting.models.nodeflow import NodeFlow, NodeFlowDataModule\n",
    "from probabilistic_flow_boosting.models.node_gmm import NodeGMM\n",
    "from probabilistic_flow_boosting.extras.datasets.uci_dataset import UCIDataSet\n",
    "from probabilistic_flow_boosting.pipelines.modeling.nodes.nodeflow import train_nodeflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parameters_nodegmm(model, X):\n",
    "    context = model.tree_model(X)\n",
    "\n",
    "    outputs = model.gauss_model.forward_layer(context)\n",
    "    outputs = outputs.reshape(model.gauss_model.n_components, 3)\n",
    "    \n",
    "    logits, means, unconstrained_stds = (\n",
    "        outputs[:, 0],\n",
    "        outputs[:, 1],\n",
    "        outputs[:, 2],\n",
    "    )\n",
    "    logits = torch.log_softmax(logits, dim=-1)\n",
    "    stds = F.softplus(unconstrained_stds) + model.gauss_model.epsilon\n",
    "    logits, means, stds = logits.detach().numpy(), means.detach().numpy(), stds.detach().numpy()\n",
    "\n",
    "    exp_logits = np.exp(logits)\n",
    "    weights = exp_logits / np.sum(exp_logits)\n",
    "    \n",
    "    return weights, means, stds\n",
    "\n",
    "\n",
    "def generate_kde_plot_gaussian(model, datamodule, observation, num_samples: int = 1000):\n",
    "    weights, means, stds = get_parameters_nodegmm(model, observation)\n",
    "    x = np.linspace(min(means) - 3 * max(stds), max(means) + 3 * max(stds), 1000)\n",
    "    \n",
    "    # Calculate the PDF values at each data point by combining Gaussian components\n",
    "    pdf_values = np.zeros_like(x)\n",
    "    for i in range(len(means)):\n",
    "        component_pdf = norm.pdf(x, loc=means[i], scale=stds[i])\n",
    "        pdf_values += component_pdf * weights[i]\n",
    "    \n",
    "    x = datamodule.target_scaler.inverse_transform(x.reshape(-1, 1))  # Rescaling target variable.\n",
    "    pdf_values *= np.abs(np.prod(datamodule.target_scaler.scale_))  # Rescaling PDF values.\n",
    "    return x, pdf_values\n",
    "\n",
    "\n",
    "def generate_samples_nodeflow(model, datamodule, observation, num_samples: int = 1000):\n",
    "    samples = model._sample(observation, num_samples)\n",
    "\n",
    "    samples_size = samples.shape\n",
    "    samples: np.ndarray = samples.detach().cpu().numpy()\n",
    "    samples: np.ndarray = samples.reshape((samples_size[0] * samples_size[1], samples_size[2]))\n",
    "    samples: np.ndarray = datamodule.target_scaler.inverse_transform(samples)\n",
    "    samples: np.ndarray = samples.reshape((samples_size[0], samples_size[1], samples_size[2]))\n",
    "    samples: np.ndarray = samples.squeeze()\n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_datasets = [\n",
    "    'concrete', \n",
    "    'energy', \n",
    "    'kin8nm', \n",
    "    'naval-propulsion-plant', \n",
    "    'power-plant', \n",
    "    'protein-tertiary-structure', \n",
    "    'wine-quality-red', \n",
    "    'yacht'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for DATASET in uci_datasets:\n",
    "    IDX = 0\n",
    "    \n",
    "    ## Load data\n",
    "    x_train = UCIDataSet(\n",
    "        filepath_data=f\"../data/01_raw/UCI/{DATASET}/data.txt\",\n",
    "        filepath_index_columns=f\"../data/01_raw/UCI/{DATASET}/index_features.txt\",\n",
    "        filepath_index_rows=f\"../data/01_raw/UCI/{DATASET}/index_train_{IDX}.txt\"\n",
    "    ).load()\n",
    "    y_train = UCIDataSet(\n",
    "        filepath_data=f\"../data/01_raw/UCI/{DATASET}/data.txt\",\n",
    "        filepath_index_columns=f\"../data/01_raw/UCI/{DATASET}/index_target.txt\",\n",
    "        filepath_index_rows=f\"../data/01_raw/UCI/{DATASET}/index_train_{IDX}.txt\"\n",
    "    ).load()\n",
    "    x_test = UCIDataSet(\n",
    "        filepath_data=f\"../data/01_raw/UCI/{DATASET}/data.txt\",\n",
    "        filepath_index_columns=f\"../data/01_raw/UCI/{DATASET}/index_features.txt\",\n",
    "        filepath_index_rows=f\"../data/01_raw/UCI/{DATASET}/index_test_{IDX}.txt\"\n",
    "    ).load()\n",
    "    y_test = UCIDataSet(\n",
    "        filepath_data=f\"../data/01_raw/UCI/{DATASET}/data.txt\",\n",
    "        filepath_index_columns=f\"../data/01_raw/UCI/{DATASET}/index_target.txt\",\n",
    "        filepath_index_rows=f\"../data/01_raw/UCI/{DATASET}/index_test_{IDX}.txt\"\n",
    "    ).load()\n",
    "\n",
    "    x_train_tensor = torch.Tensor(x_train.values)\n",
    "    x_test_tensor = torch.Tensor(x_test.values)\n",
    "    y_train_tensor = torch.Tensor(y_train.values)\n",
    "    y_test_tensor = torch.Tensor(y_test.values)\n",
    "\n",
    "    datamodule = NodeFlowDataModule(x_train, y_train, x_test, y_test, split_size=0.8, batch_size=2048)\n",
    "    datamodule.target_scaler.fit(datamodule.y_tr)\n",
    "\n",
    "\n",
    "    ## Load models\n",
    "    model_filepath = f\"../models/nodegmm_1d/UCI/{DATASET}/model_nodegmm_1d_{IDX}-nodegmm.pt\"\n",
    "    nodegauss = torch.load(model_filepath, map_location=\"cpu\")\n",
    "    nodegauss.eval()\n",
    "    \n",
    "    model_filepath = f\"../models/nodegmm/UCI/{DATASET}/model_nodegmm_{IDX}-nodegmm.pt\"\n",
    "    nodegmm = torch.load(model_filepath, map_location=\"cpu\")\n",
    "    nodegmm.eval()\n",
    "\n",
    "    model_filepath = f\"../models/nodeflow/UCI/{DATASET}/model_{IDX}\"\n",
    "    nodeflow = NodeFlow.load(model_filepath, map_location=\"cpu\")\n",
    "    nodeflow.eval()\n",
    "\n",
    "    ## Do things\n",
    "    for i in range(1):\n",
    "        print(DATASET, i)\n",
    "        observation = x_test_tensor[i, :].reshape(1, -1)\n",
    "        \n",
    "        nodegauss_x, nodegauss_pdf_values  = generate_kde_plot_gaussian(nodegauss, datamodule, observation, num_samples=1000)\n",
    "        nodegmm_x, nodegmm_pdf_values = generate_kde_plot_gaussian(nodegmm, datamodule, observation, num_samples=1000)\n",
    "\n",
    "        nodeflow_samples = generate_samples_nodeflow(nodeflow, datamodule, observation, num_samples=1000)\n",
    "\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.axvline(x=y_test_tensor[i].item(), color='r', label='True value')\n",
    "        plt.plot(nodegauss_x, nodegauss_pdf_values, color = \"green\", label=\"NodeGauss\")\n",
    "        plt.plot(nodegmm_x, nodegmm_pdf_values, color = \"orange\", label=\"NodeGMM\")\n",
    "        sns.kdeplot(nodeflow_samples, color=\"blue\", label=\"NodeFlow\")\n",
    "        \n",
    "        plt.xlabel(\"Y\")\n",
    "        plt.ylabel(\"Probability Density\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"../figures/distribution/{DATASET}_{i}.pdf\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
