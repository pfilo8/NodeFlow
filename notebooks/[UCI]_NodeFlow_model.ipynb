{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext kedro.extras.extensions.ipython\n",
    "# %reload_kedro /home/ofurman/Probabilistic-Flow-Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ofurman/Probabilistic-Flow-Boosting/venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ofurman/Probabilistic-Flow-Boosting/venv/lib/python3.8/site-packages/lightning_fabric/__init__.py:36: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('lightning_fabric')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n",
      "/home/ofurman/Probabilistic-Flow-Boosting/venv/lib/python3.8/site-packages/pytorch_lightning/__init__.py:36: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pytorch_lightning')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  __import__(\"pkg_resources\").declare_namespace(__name__)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from probabilistic_flow_boosting.models.nodeflow import NodeFlow, NodeFlowDataModule\n",
    "from probabilistic_flow_boosting.models.node_gmm import NodeGMM\n",
    "from probabilistic_flow_boosting.extras.datasets.uci_dataset import UCIDataSet\n",
    "from probabilistic_flow_boosting.pipelines.modeling.nodes.nodeflow import train_nodeflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = UCIDataSet(\n",
    "    filepath_data=\"../data/01_raw/UCI/energy/data.txt\",\n",
    "    filepath_index_columns=\"../data/01_raw/UCI/energy/index_features.txt\",\n",
    "    filepath_index_rows=\"../data/01_raw/UCI/energy/index_train_0.txt\"\n",
    ").load()\n",
    "y_train = UCIDataSet(\n",
    "    filepath_data=\"../data/01_raw/UCI/energy/data.txt\",\n",
    "    filepath_index_columns=\"../data/01_raw/UCI/energy/index_target.txt\",\n",
    "    filepath_index_rows=\"../data/01_raw/UCI/energy/index_train_0.txt\"\n",
    ").load()\n",
    "\n",
    "x_test = UCIDataSet(\n",
    "    filepath_data=\"../data/01_raw/UCI/energy/data.txt\",\n",
    "    filepath_index_columns=\"../data/01_raw/UCI/energy/index_features.txt\",\n",
    "    filepath_index_rows=\"../data/01_raw/UCI/energy/index_test_0.txt\"\n",
    ").load()\n",
    "y_test = UCIDataSet(\n",
    "    filepath_data=\"../data/01_raw/UCI/energy/data.txt\",\n",
    "    filepath_index_columns=\"../data/01_raw/UCI/energy/index_target.txt\",\n",
    "    filepath_index_rows=\"../data/01_raw/UCI/energy/index_test_0.txt\"\n",
    ").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeFlow(\n",
       "  (tree_model): DenseODSTBlock(\n",
       "    (0): ODST(in_features=8, num_trees=200, depth=4, tree_dim=2, flatten_output=True)\n",
       "    (1): ODST(in_features=408, num_trees=200, depth=4, tree_dim=2, flatten_output=True)\n",
       "    (2): ODST(in_features=808, num_trees=200, depth=4, tree_dim=2, flatten_output=True)\n",
       "    (3): ODST(in_features=1208, num_trees=200, depth=4, tree_dim=2, flatten_output=True)\n",
       "  )\n",
       "  (flow_model): ContinuousNormalizingFlow(\n",
       "    (flow): SequentialFlow(\n",
       "      (chain): ModuleList(\n",
       "        (0): MovingBatchNorm1d(1, eps=0.0001, decay=0.1, bn_lag=0.0, affine=True)\n",
       "        (1): CNF(\n",
       "          (odefunc): ODEfunc(\n",
       "            (diffeq): ODEnet(\n",
       "              (layers): ModuleList(\n",
       "                (0): ConcatSquashLinear(\n",
       "                  (_layer): Linear(in_features=1, out_features=4, bias=True)\n",
       "                  (_hyper_bias): Linear(in_features=1601, out_features=4, bias=False)\n",
       "                  (_hyper_gate): Linear(in_features=1601, out_features=4, bias=True)\n",
       "                )\n",
       "                (1): ConcatSquashLinear(\n",
       "                  (_layer): Linear(in_features=4, out_features=4, bias=True)\n",
       "                  (_hyper_bias): Linear(in_features=1601, out_features=4, bias=False)\n",
       "                  (_hyper_gate): Linear(in_features=1601, out_features=4, bias=True)\n",
       "                )\n",
       "                (2): ConcatSquashLinear(\n",
       "                  (_layer): Linear(in_features=4, out_features=1, bias=True)\n",
       "                  (_hyper_bias): Linear(in_features=1601, out_features=1, bias=False)\n",
       "                  (_hyper_gate): Linear(in_features=1601, out_features=1, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (activation_fns): ModuleList(\n",
       "                (0-1): 2 x Tanh()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): MovingBatchNorm1d(1, eps=0.0001, decay=0.1, bn_lag=0.0, affine=True)\n",
       "        (3): CNF(\n",
       "          (odefunc): ODEfunc(\n",
       "            (diffeq): ODEnet(\n",
       "              (layers): ModuleList(\n",
       "                (0): ConcatSquashLinear(\n",
       "                  (_layer): Linear(in_features=1, out_features=4, bias=True)\n",
       "                  (_hyper_bias): Linear(in_features=1601, out_features=4, bias=False)\n",
       "                  (_hyper_gate): Linear(in_features=1601, out_features=4, bias=True)\n",
       "                )\n",
       "                (1): ConcatSquashLinear(\n",
       "                  (_layer): Linear(in_features=4, out_features=4, bias=True)\n",
       "                  (_hyper_bias): Linear(in_features=1601, out_features=4, bias=False)\n",
       "                  (_hyper_gate): Linear(in_features=1601, out_features=4, bias=True)\n",
       "                )\n",
       "                (2): ConcatSquashLinear(\n",
       "                  (_layer): Linear(in_features=4, out_features=1, bias=True)\n",
       "                  (_hyper_bias): Linear(in_features=1601, out_features=1, bias=False)\n",
       "                  (_hyper_gate): Linear(in_features=1601, out_features=1, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (activation_fns): ModuleList(\n",
       "                (0-1): 2 x Tanh()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): MovingBatchNorm1d(1, eps=0.0001, decay=0.1, bn_lag=0.0, affine=True)\n",
       "        (5): CNF(\n",
       "          (odefunc): ODEfunc(\n",
       "            (diffeq): ODEnet(\n",
       "              (layers): ModuleList(\n",
       "                (0): ConcatSquashLinear(\n",
       "                  (_layer): Linear(in_features=1, out_features=4, bias=True)\n",
       "                  (_hyper_bias): Linear(in_features=1601, out_features=4, bias=False)\n",
       "                  (_hyper_gate): Linear(in_features=1601, out_features=4, bias=True)\n",
       "                )\n",
       "                (1): ConcatSquashLinear(\n",
       "                  (_layer): Linear(in_features=4, out_features=4, bias=True)\n",
       "                  (_hyper_bias): Linear(in_features=1601, out_features=4, bias=False)\n",
       "                  (_hyper_gate): Linear(in_features=1601, out_features=4, bias=True)\n",
       "                )\n",
       "                (2): ConcatSquashLinear(\n",
       "                  (_layer): Linear(in_features=4, out_features=1, bias=True)\n",
       "                  (_hyper_bias): Linear(in_features=1601, out_features=1, bias=False)\n",
       "                  (_hyper_gate): Linear(in_features=1601, out_features=1, bias=True)\n",
       "                )\n",
       "              )\n",
       "              (activation_fns): ModuleList(\n",
       "                (0-1): 2 x Tanh()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): MovingBatchNorm1d(1, eps=0.0001, decay=0.1, bn_lag=0.0, affine=True)\n",
       "      )\n",
       "    )\n",
       "    (distribution): StandardNormal()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule = NodeFlowDataModule(x_train, y_train, x_test, y_test, split_size=0.8, batch_size=2048)\n",
    "\n",
    "model_filepath = \"../data/06_models/UCI/energy/model_0\"\n",
    "NodeFlow.load(model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /home/ofurman/Probabilistic-Flow-Boosting/notebooks/lightning_logs\n",
      "/home/ofurman/Probabilistic-Flow-Boosting/venv/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/home/ofurman/Probabilistic-Flow-Boosting/venv/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  ) < LooseVersion(\"1.15\"):\n",
      "/home/ofurman/Probabilistic-Flow-Boosting/venv/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:2663: UserWarning: n_quantiles (1000) is greater than the total number of samples (552). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name       | Type                      | Params\n",
      "---------------------------------------------------------\n",
      "0 | tree_model | DenseODSTBlock            | 2.0 M \n",
      "1 | flow_model | ContinuousNormalizingFlow | 86.6 K\n",
      "---------------------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "516       Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.259     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ofurman/Probabilistic-Flow-Boosting/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/ofurman/Probabilistic-Flow-Boosting/notebooks/../src/probabilistic_flow_boosting/models/node/odst.py:143: UserWarning: Data-aware initialization is performed on less than 1000 data points. This may cause instability.To avoid potential problems, run this model on a data batch with at least 1000 data samples.You can do so manually before training. Use with torch.no_grad() for memory efficiency.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ofurman/Probabilistic-Flow-Boosting/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/ofurman/Probabilistic-Flow-Boosting/venv/lib/python3.8/site-packages/lightning/pytorch/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:02<00:00,  2.20s/it, v_num=0, val_nll=3.290, train_nll=3.340]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ofurman/Probabilistic-Flow-Boosting/venv/lib/python3.8/site-packages/lightning/pytorch/trainer/call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "model_params = {\n",
    "        \"num_layers\": 4,\n",
    "        \"depth\": 4,\n",
    "        \"tree_output_dim\": 2,\n",
    "        \"num_trees\": 200,\n",
    "        \"flow_hidden_dims\": [4,4]\n",
    "}\n",
    "\n",
    "best_model_path = train_nodeflow(\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    n_epochs=400,\n",
    "    patience=40,\n",
    "    split_size=0.8,\n",
    "    batch_size=2048,\n",
    "    model_hyperparams=model_params\n",
    ")\n",
    "model = NodeFlow.load_from_checkpoint(best_model_path, input_dim=x_train.shape[1], output_dim=y_train.shape[1], **model_params)\n",
    "os.remove(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
